package main

import (
	"context"
	"fmt"
	"log"
	"net/url"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/chromedp/cdproto/network"
	"github.com/chromedp/cdproto/page"
	"github.com/chromedp/chromedp"
	"github.com/pdfcpu/pdfcpu/pkg/api"
	"github.com/pdfcpu/pdfcpu/pkg/pdfcpu/model"
)

const (
	BaseURL       = "https://mo-mi.gitbook.io/xiaomomi-plugins/customcrops"
	OutDir        = "dist"
	FinalPDF      = "MOMI_CustomCrops_Wiki.pdf"
	// ç¨³å®šæ€§æ ¸å¿ƒï¼šåœ¨ GitHub Actions ä¸­å»ºè®®è®¾ä¸º 1 æˆ– 2ï¼Œé˜²æ­¢æµè§ˆå™¨å´©æºƒ
	MaxConcurrent = 1 
	UserAgent     = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
)

func main() {
	start := time.Now()
	os.RemoveAll(OutDir)
	os.MkdirAll(OutDir, 0755)

	opts := append(chromedp.DefaultExecAllocatorOptions[:],
		chromedp.Flag("headless", "new"),
		chromedp.Flag("no-sandbox", true),
		chromedp.Flag("disable-dev-shm-usage", true),
		chromedp.Flag("disable-gpu", true),
		chromedp.UserAgent(UserAgent),
	)

	allocCtx, cancel := chromedp.NewExecAllocator(context.Background(), opts...)
	defer cancel()

	fmt.Println("ğŸ” æ­£åœ¨æ‰«æ GitBook ç›®å½•ç»“æ„...")
	uniqueUrls := scanLinksDeep(allocCtx)
	
	if len(uniqueUrls) == 0 {
		fmt.Println("âŒ é”™è¯¯ï¼šæœªèƒ½è·å–æœ‰æ•ˆé“¾æ¥ã€‚")
		os.Exit(1)
	}

	fmt.Printf("âœ… å‘ç° %d ä¸ªæ–‡æ¡£é¡µé¢ï¼Œå¼€å§‹ä¸²è¡Œç¨³å®šæ¸²æŸ“...\n", len(uniqueUrls))

	taskChan := make(chan Task, len(uniqueUrls))
	resChan := make(chan Result, len(uniqueUrls))
	var wg sync.WaitGroup

	for i := 0; i < MaxConcurrent; i++ {
		wg.Add(1)
		go worker(allocCtx, taskChan, resChan, &wg)
	}

	for i, u := range uniqueUrls {
		taskChan <- Task{ID: i, URL: u}
	}
	close(taskChan)
	wg.Wait()
	close(resChan)

	var results []Result
	for r := range resChan {
		results = append(results, r)
	}
	sort.Slice(results, func(i, j int) bool { return results[i].ID < results[j].ID })

	if len(results) == 0 {
		fmt.Println("âŒ é”™è¯¯ï¼šæ‰€æœ‰é¡µé¢æ¸²æŸ“å‡å¤±è´¥ï¼Œæ— æ³•åˆå¹¶ã€‚")
		os.Exit(1)
	}

	mergePDFs(results)
	fmt.Printf("\nğŸ† å®Œæˆï¼æˆåŠŸæ¸²æŸ“ %d/%d é¡µ | è€—æ—¶: %s\n", len(results), len(uniqueUrls), time.Since(start))
}

func worker(parentCtx context.Context, tasks <-chan Task, results chan<- Result, wg *sync.WaitGroup) {
	defer wg.Done()

	for t := range tasks {
		success := false
		var buf []byte
		
		// è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼šæœ€å¤šå°è¯• 3 æ¬¡
		for attempt := 1; attempt <= 3; attempt++ {
			if attempt > 1 {
				fmt.Printf("ğŸ”„ [%d] æ­£åœ¨è¿›è¡Œç¬¬ %d æ¬¡é‡è¯•...\n", t.ID, attempt)
				time.Sleep(2 * time.Second)
			}

			// ä¸ºæ¯æ¬¡æ¸²æŸ“åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„ Contextï¼Œé˜²æ­¢äº’ç›¸å¹²æ‰°
			ctx, cancel := chromedp.NewContext(parentCtx)
			tCtx, tCancel := context.WithTimeout(ctx, 60*time.Second)
			
			err := chromedp.Run(tCtx,
				network.Enable(),
				chromedp.Navigate(t.URL),
				// GitBook åŠ è½½è¾ƒæ…¢ï¼Œç­‰å¾… body å‡ºç°å³å¯
				chromedp.WaitReady("body"),
				chromedp.Sleep(5*time.Second), // ç•™å‡ºè¶³å¤Ÿæ—¶é—´ç»™åŠ¨æ€å†…å®¹
				chromedp.Evaluate(CleanScript, nil),
				chromedp.ActionFunc(func(ctx context.Context) error {
					var err error
					buf, _, err = page.PrintToPDF().
						WithPrintBackground(true).
						WithPaperWidth(8.27).
						WithPaperHeight(11.69).
						Do(ctx)
					return err
				}),
			)
			tCancel()
			cancel() // æ¸²æŸ“å®Œç«‹å³é‡Šæ”¾æµè§ˆå™¨ Tab å†…å­˜

			if err == nil {
				success = true
				break
			}
			fmt.Printf("âš ï¸ [%d] å°è¯• %d å¤±è´¥: %v\n", t.ID, attempt, err)
		}

		if success {
			path := filepath.Join(OutDir, fmt.Sprintf("%03d.pdf", t.ID))
			os.WriteFile(path, buf, 0644)
			results <- Result{ID: t.ID, Path: path}
			fmt.Printf("ğŸ“„ [%d] æ¸²æŸ“æˆåŠŸ: %s\n", t.ID, t.URL)
		} else {
			fmt.Printf("âŒ [%d] æœ€ç»ˆæ¸²æŸ“å¤±è´¥: %s\n", t.ID, t.URL)
		}
	}
}

func scanLinksDeep(ctx context.Context) []string {
	// æ‰«æä½¿ç”¨ç‹¬ç«‹çš„ Context
	sCtx, sCancel := chromedp.NewContext(ctx)
	defer sCancel()
	
	visited := make(map[string]bool)
	var links []string
	queue := []string{BaseURL}
	targetHost := "mo-mi.gitbook.io"

	for len(queue) > 0 {
		curr := queue[0]
		queue = queue[1:]

		u, _ := url.Parse(curr)
		cleanURL := u.Scheme + "://" + u.Host + u.Path
		cleanURL = strings.TrimSuffix(cleanURL, "/")

		if visited[cleanURL] { continue }
		visited[cleanURL] = true

		fmt.Printf("ğŸ”— æ­£åœ¨æ‰«æ: %s\n", cleanURL)

		var res []string
		tCtx, tCancel := context.WithTimeout(sCtx, 30*time.Second)
		err := chromedp.Run(tCtx, 
			chromedp.Navigate(curr),
			chromedp.WaitReady("body"),
			chromedp.Sleep(3*time.Second),
			chromedp.Evaluate(`
				Array.from(document.querySelectorAll('a[href]'))
					.map(a => a.href)
			`, &res),
		)
		tCancel()

		if err != nil {
			fmt.Printf("âš ï¸ æ‰«æé¡µé¢å‡ºé”™ (è·³è¿‡): %v\n", err)
			continue
		}

		for _, l := range res {
			parsed, err := url.Parse(l)
			if err != nil { continue }

			if parsed.Host == targetHost && strings.Contains(parsed.Path, "customcrops") {
				parsed.Fragment = ""
				parsed.RawQuery = ""
				full := strings.TrimSuffix(parsed.String(), "/")

				if !visited[full] {
					links = append(links, full)
					queue = append(queue, full)
				}
			}
		}
	}
	return uniqueAndSort(links)
}

const CleanScript = `
	(function() {
		// å½»åº•ç§»é™¤å¹²æ‰°å…ƒç´ 
		const selectors = ['header', 'nav', '[role="navigation"]', '#feedback-buoy', 'footer', 'iframe'];
		selectors.forEach(s => document.querySelectorAll(s).forEach(e => e.remove()));

		const main = document.querySelector('main');
		if(main) {
			main.style.width = '100%';
			main.style.maxWidth = 'none';
			main.style.margin = '0';
			main.style.padding = '30px';
		}
		document.body.style.backgroundColor = 'white';
	})();
`

func mergePDFs(results []Result) {
	var inFiles []string
	for _, r := range results { inFiles = append(inFiles, r.Path) }
	conf := model.NewDefaultConfiguration()
	conf.ValidationMode = model.ValidationRelaxed 
	api.MergeCreateFile(inFiles, FinalPDF, false, conf)
}

func uniqueAndSort(slice []string) []string {
	m := make(map[string]bool)
	var list []string
	for _, v := range slice {
		if !m[v] && v != "" {
			m[v] = true
			list = append(list, v)
		}
	}
	sort.Strings(list)
	return list
}

type Task struct {
	ID  int
	URL string
}

type Result struct {
	ID   int
	Path string
}
